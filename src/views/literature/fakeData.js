let fakeArticleDetail={
    // authors: [
    //   "University of Warsaw",
    //   "Facebook",
    //   "Salesforce.com",
    //   "University of Washington",
    //   "Nvidia",
    //   "Mario Negri Institute for Pharmacological Research",
    //   "University of Oxford",
    //   "ETH Zurich",
    //   "Stanford University",
    //   "Twitter",
    //   "Tsinghua University"
    // ],
    portals: [
      {
        portal_id: "24112262481",
        portal_name: "AdamPaszke1",
      },
      {
        portal_id: "24112262482",
        portal_name: "AdamPaszke2",
      },
      {
        portal_id: "24112262483",
        portal_name: "AdamPaszke3",
      },
    ],
    fields: [
      {
        field_id: "123123",
        field_name: "Computer Vision"
      },
      {
        field_id: "123124",
        field_name: "Computer Network"
      },
    ],
    citation_count: 8,
    collect_count: 16,
    doi: "10.1051/epjconf/202024507021",
    data_id: "9782951d43920382d2f1229601d018ca87df4dcb",
    venue_id: "asasasas1212",
    venue_name: "Elsevier BV EPJ Web of Conferences",
    conference: "",
    abstract: "The Centralised Elasticsearch Service at CERN runs the infrastructure to provide Elasticsearch clusters for more than 100 different use cases.This contribution presents how the infrastructure is managed, covering the resource distribution, instance creation, cluster monitoring and user support. The contribution will present the components that have been identified as critical in order to share resources and minimise the amount of clusters and machines needed to run the service. In particular, all the automation for the instance configuration, including index template management, backups and visualisation settings, will be explained in detail.",
    pdfs: [
      "https://www.pap.es/files/1116-877-pdf/990.pdf"
    ],
    view_url: "https://dialnet.unirioja.es/servlet/articulo?codigo=2946216",
    citation_msg: [
      {
        authors: [
          {
            author_id: "2772667878",
            author_name: "Sepp Hochreiter",
          },
          {
            author_id: "2772667878",
            author_name: "Jürgen Schmidhuber",
          }
        ],
        citation_count: 1,
        id: "d884573116a4363256d52575a4dd642f3b5b6f24",
        journalName: "EPJ Web of Conferences",
        abstract: "In early 2016 CERN IT created a new project to consolidate and centralise Elas-ticsearch instances across the site, with the aim to offer a production quality new IT services to experiments and departments. We present the solutions we adapted for securing the system using open source only tools, which allows us to consolidate up to 20 different use cases on a single Elasticsearch cluster.",
        reference_count: 2,
        paper_title: "Securing and sharing Elasticsearch resources with Read-onlyREST",
        year: 2019
      },
    ],
    related_papers: [
      {
        authors: [
          {
            author_id: "2772667878",
            author_name: "Sepp Hochreiter",
          },
          {
            author_id: "2772667878",
            author_name: "Jürgen Schmidhuber",
          }
        ],
        citation_count: 1,
        id: "d884573116a4363256d52575a4dd642f3b5b6f24",
        journalName: "EPJ Web of Conferences",
        abstract: "In early 2016 CERN IT created a new project to consolidate and centralise Elas-ticsearch instances across the site, with the aim to offer a production quality new IT services to experiments and departments. We present the solutions we adapted for securing the system using open source only tools, which allows us to consolidate up to 20 different use cases on a single Elasticsearch cluster.",
        reference_count: 2,
        paper_title: "Securing and sharing Elasticsearch resources with Read-onlyREST",
        year: 2019
      },
      {
        authors: [
          {
            author_id: "2772667878",
            author_name: "Sepp Hochreiter",
          },
          {
            author_id: "2772667878",
            author_name: "Jürgen Schmidhuber",
          }
        ],
        citation_count: 1,
        id: "d884573116a4363256d52575a4dd642f3b5b6f24",
        journalName: "EPJ Web of Conferences",
        abstract: "In early 2016 CERN IT created a new project to consolidate and centralise Elas-ticsearch instances across the site, with the aim to offer a production quality new IT services to experiments and departments. We present the solutions we adapted for securing the system using open source only tools, which allows us to consolidate up to 20 different use cases on a single Elasticsearch cluster.",
        reference_count: 2,
        paper_title: "Securing and sharing Elasticsearch resources with Read-onlyREST",
        year: 2019
      },
    ],
    reference_msg: [
      {
        authors: [
          {
            author_id: "2772667878",
            author_name: "Sepp Hochreiter",
          },
          {
            author_id: "2772667878",
            author_name: "Jürgen Schmidhuber",
          }
        ],
        citation_count: 1,
        id: "d884573116a4363256d52575a4dd642f3b5b6f24",
        journalName: "EPJ Web of Conferences",
        abstract: "In early 2016 CERN IT created a new project to consolidate and centralise Elas-ticsearch instances across the site, with the aim to offer a production quality new IT services to experiments and departments. We present the solutions we adapted for securing the system using open source only tools, which allows us to consolidate up to 20 different use cases on a single Elasticsearch cluster.",
        reference_count: 2,
        paper_title: "Securing and sharing Elasticsearch resources with Read-onlyREST",
        year: 2019
      },
      {
        authors: [
          {
            author_id: "2772667878",
            author_name: "Sepp Hochreiter",
          },
          {
            author_id: "2772667878",
            author_name: "Jürgen Schmidhuber",
          }
        ],
        citation_count: 44135,
        id: "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
        journalName: "Neural Computation",
        abstract: "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.",
        reference_count: 42,
        paper_title: "Long Short-Term Memory",
        year: 1997
      }
    ],
    reference_count: 2,
    title: "Large Elasticsearch cluster management",
    date: 2020,
  }


  let fakeComments=[
    {
      comment_id: 1,
      user_id: 2,
      username: "syt",
      content: "终于收到我需要的宝贝了，东西很好，价美物廉，谢谢掌柜的!说实在，这是我淘宝购物来让我最满意的一次购物。无论是掌柜的态度还是对物品，我都非常满意的。",
      time: "2021-11-23T23:09:56+08:00",
      data_id:"9782951d43920382d2f1229601d018ca87df4dcb",
      comment2_list:[
        {
          comment_id: 2, //评论id（对评论的评论）
          user_id: '2',  //评论人id
          username: 'syt1', //评论人name
          content: '评论内容',
          time: "2021-11-24T23:09:56+08:00",
          comment1_id: 2,
          reply_to_id: 2,
          reply_to_name: "syt",
          layer: 2,//评论层级 1 2
        }
      ]
    }
  ]


  let fetchFakeArticleDetail = new Promise(function(resolve,reject){
    let res = {
        data:{
            status:200,
            details:fakeArticleDetail,
        }
    }
    resolve(res)
})

let fetchFakeComments = new Promise(function(resolve,reject){
  let res = {
      data:{
          status:200,
          details:fakeComments,
      }
  }
  resolve(res)
})

  export {fakeArticleDetail, fakeComments,fetchFakeArticleDetail,fetchFakeComments}